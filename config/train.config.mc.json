{
    "output_dir": "models/DialoGPT-finetuned-multiCONAN",
    "evaluation_strategy": "epoch",
    "logging_strategy": "epoch",
    "save_strategy": "epoch",
    "save_total_limit": 1,
    "load_best_model_at_end": true,
    "metric_for_best_model": "loss",
    "learning_rate": 5e-5,
    "num_train_epochs": 5,
    "per_device_train_batch_size": 32,
    "per_device_eval_batch_size": 256,
    "report_to": "wandb"
}
